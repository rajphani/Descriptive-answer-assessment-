{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuestionAssessment.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "6rwTRbTDPA37",
        "colab_type": "code",
        "outputId": "9b00c38b-95fc-4daf-9ba6-e1ef9d2c34b0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.seterr(divide='ignore', invalid='ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 771
        }
      ]
    },
    {
      "metadata": {
        "id": "i5J0vOLUPA4E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re, math\n",
        "import nltk\n",
        "import numpy as np\n",
        "import wikipedia\n",
        "\n",
        "from dateutil import parser\n",
        "from collections import Counter\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gingerit.gingerit import GingerIt\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# n-gram individual BLEU---Word Order\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "    \n",
        "#importing libraries\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UigLj948PA4I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lsa(text):\n",
        "    \n",
        "    stopset = set(stopwords.words('english'))\n",
        "    text=[text]\n",
        "    \n",
        "    #scikit-learn's TF-IDF vectorizer\n",
        "    vectorizer = TfidfVectorizer(stop_words=stopset, use_idf=True, ngram_range=(1, 3))\n",
        "    X = vectorizer.fit_transform(text)\n",
        "    #X[0]   #sparse matrix\n",
        "    #print(X[0])\n",
        "    \n",
        "    lsa = TruncatedSVD(n_components=2, n_iter=100)\n",
        "    lsa.fit(X)\n",
        "    terms = vectorizer.get_feature_names()\n",
        "    for i, comp in enumerate(lsa.components_): \n",
        "        termsInComp = zip (terms,comp)\n",
        "        sortedTerms =  sorted(termsInComp, key=lambda x: x[1], reverse=True) [:20]\n",
        "        \n",
        "    return sortedTerms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FMXS1NGdPA4L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def text_to_vector(text):\n",
        "    WORD = re.compile(r'\\w+')\n",
        "    words = WORD.findall(text)\n",
        "    return Counter(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0H13NLlkPA4O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model_answer(key_text):\n",
        "    key_wiki = (wikipedia.page(key_text))\n",
        "    model_answer = key_wiki.content\n",
        "    #print(modelanswer)    \n",
        "    return model_answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gV0D5HotPA4R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cosine(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ljW45UqPPA4U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gram(text):\n",
        "    \n",
        "    parser = GingerIt()\n",
        "    a=parser.parse(text+\".\")\n",
        "    \n",
        "    check=a['result']\n",
        "    return check\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0KIAMZ4lPA4X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cal_spgm(user_answer):\n",
        "    regex = re.compile(\"([\\(\\[]).*?([\\)\\]])\")\n",
        "    ratio_spgm=[]\n",
        "    \n",
        "    for sent in user_answer.split(\".\"):\n",
        "        if( len(sent) != 0):\n",
        "            result = re.sub( regex, \"\", sent)\n",
        "            corrected_user_answer = gram(result)\n",
        "            ratio_spgm.append( SequenceMatcher(None, corrected_user_answer, result).ratio())\n",
        "    \n",
        "    ratio_spgm = np.mean(ratio_spgm)\n",
        "    print(\"Spelling and Grammer Score: %s\"%(ratio_spgm)) \n",
        "    return ratio_spgm, corrected_user_answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iwyf1RS2PA4a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cal_lsa(model_answer, user_answer):\n",
        "    ma = dict(lsa(model_answer))\n",
        "    #print(ma)\n",
        "    ua = dict(lsa(user_answer))\n",
        "    #print(ua)\n",
        "    \n",
        "    num_items = {k: ua[k] for k in ma if k in ua}\n",
        "    score_lsa=0\n",
        "    sum=0\n",
        "    for key in num_items:\n",
        "\n",
        "        if(num_items[key]>ma[key]):\n",
        "            sum=sum+((2*ma[key])-num_items[key])\n",
        "        else:\n",
        "            sum=sum+(num_items[key]/ma[key])\n",
        "    ratio_lsa=sum/(len(ua)-1)\n",
        "    print(\"LSA Score: %s\"%(ratio_lsa)) \n",
        "\n",
        "    return ratio_lsa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7p_aFbdlPA4c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cal_SentenceSimilarity( modelanswer, useranswer):\n",
        "    #Sentence similarity\n",
        "    list_ma = modelanswer.split(\".\")\n",
        "    list_ua = useranswer.split(\".\") \n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    ss_mean=0\n",
        "    sum=0\n",
        "    \n",
        "    for j in range(0,len(list_ua)):\n",
        "        if (len(list_ua[j])>10):\n",
        "            max=0\n",
        "            for i in range(0,len(list_ma)):\n",
        "                corpus = [list_ma[i],list_ua[j]]\n",
        "                tfidf = vectorizer.fit_transform(corpus)\n",
        "                words = vectorizer.get_feature_names()\n",
        "                similarity_matrix = cosine_similarity(tfidf)\n",
        "                if(similarity_matrix[0][1]>max):\n",
        "                    max=similarity_matrix[0][1]\n",
        "            sum = sum + max\n",
        "\n",
        "    ss_mean = sum /(len(list_ua) - 1)\n",
        "    print(\"Sentence Similarity Score: %s\"%(ss_mean))\n",
        "    \n",
        "    chencherry = SmoothingFunction()\n",
        "    result=0.0\n",
        "    sum=0.0\n",
        "    for j in range(0,len(u)):\n",
        "        if(len(u[j])!=0):\n",
        "            max=0\n",
        "            for i in range(0,len(m)):\n",
        "                mm=list(m[i].split(\" \"))\n",
        "            result=sentence_bleu(m[i], u[j], weights=(1, 0, 0, 0),smoothing_function=chencherry.method1)           \n",
        "            sum=sum+result\n",
        "\n",
        "    result=sum/(len(u)-1)\n",
        "    print(\"BLEU Score: %s\"%(result)) \n",
        "    \n",
        "    return ss_mean, result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P7VnPNUvPA4f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cal_date( modelanswer, useranswer):\n",
        "    re_day = r\"0[1-9]|[12][0-9]|3[01]\"\n",
        "    re_days = r\"[1-9]|[12][0-9]|3[01]\"\n",
        "    re_month_digits = r\"0[1-9]|1[0-2]\"\n",
        "    re_month_char = r\"January|Febuary|March|April|May|June|July|August|September|October|November|December\"\n",
        "    re_month_char_short = r\"Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec\"\n",
        "    re_year_4_digits = r\"0[0-9][0-9][1-9]|[1-9][0-9][0-9][0-9]\"\n",
        "    re_year_2_digits = r\"0[1-9]|[1-9][0-9]\"\n",
        "\n",
        "    pattern_ddmmyy = r\"(?:(?:%s)[/\\.-](?:%s)[/\\.-](?:%s))\"%( re_day, re_month_digits, re_year_2_digits)\n",
        "    pattern_ddmmyyyy = r\"(?:(?:%s)[/\\.-](?:%s)[/\\.-](?:%s))\"%( re_day, re_month_digits, re_year_4_digits)\n",
        "    pattern_yyyymmdd = r\"(?:(?:%s)[/\\.-](?:%s)[/\\.-](?:%s))\"%( re_year_4_digits, re_month_digits, re_day)\n",
        "    pattern_mddyyyy = r\"(?:(?:%s) (?:%s), (?:%s))\"%( re_month_char, re_day, re_year_4_digits)\n",
        "    pattern_ddmmmyyyy = r\"(?:(?:%s) (?:%s), (?:%s))\"%( re_day, re_month_char_short, re_year_4_digits)\n",
        "    repl_pat=r\"(?:(?:%s) (?:%s) (?:%s))\"%( re_day, re_month_char, re_year_4_digits)\n",
        "    repl_pat_n=r\"(?:(?:%s) (?:%s) (?:%s))\"%( re_days, re_month_char, re_year_4_digits)\n",
        "    pattern_date_all = r\"%s|%s|%s|%s|%s|%s|%s\"%(pattern_ddmmyy, pattern_ddmmyyyy, pattern_yyyymmdd, pattern_mddyyyy, pattern_ddmmmyyyy,repl_pat,repl_pat_n)\n",
        "    \n",
        "    lst_ul=[]\n",
        "    lst_ml=[]\n",
        "    sent_dt_lst={}\n",
        "    user_dt_lst={}\n",
        "    date_res=0.0\n",
        "    final_dt_res=0.0\n",
        "    countt=0.0 \n",
        "    \n",
        "    lst_m=re.findall(pattern_date_all,modelanswer)\n",
        "    for i in lst_m:\n",
        "        d = parser.parse(i)\n",
        "        lst_ml.append(d.strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "    lst_u=re.findall(pattern_date_all,useranswer)\n",
        "    for i in lst_u:\n",
        "        d = parser.parse(i)\n",
        "        #if(d.strftime(\"%Y-%m-%d\") in lst_ml)\n",
        "\n",
        "    for sent in modelanswer.split(\".\"):   \n",
        "        dates=re.findall(pattern_date_all,sent)\n",
        "        if(dates):\n",
        "            for date in dates:\n",
        "                if (date in sent_dt_lst):\n",
        "                    sent_dt_lst[date]=sent_dt_lst[date]+\".\"+sent\n",
        "                else:\n",
        "                    sent_dt_lst[date]=sent\n",
        "\n",
        "\n",
        "\n",
        "    for sent in useranswer.split(\".\"): \n",
        "        dates=re.findall(pattern_date_all,sent)\n",
        "\n",
        "        if len(dates)!=0:\n",
        "            for date in dates:\n",
        "                if date in sent_dt_lst.keys():\n",
        "                    countt=countt+1\n",
        "                    date_res+=SequenceMatcher(None, sent, sent_dt_lst[date]).ratio()\n",
        "    if(countt!=0):\n",
        "        final_dt_res=date_res/countt\n",
        "    else:\n",
        "        final_dt_res = 0\n",
        "        \n",
        "    print(\"Date Score: %s\"%(final_dt_res)) \n",
        "    return final_dt_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HvCWPRNTPA4h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cal_score( model_answer, user_answer):\n",
        "    final_score = 0.0\n",
        "    spgm_score = 0.0\n",
        "    lsa_score = 0.0\n",
        "    ss_score = 0.0\n",
        "    bleu_score = 0.0\n",
        "    dt_score = 0.0\n",
        "    \n",
        "    #Check Grammer\n",
        "    spgm_score, corrected_user_answer = cal_spgm(user_answer)\n",
        "    \n",
        "    #Calculate LSA Score\n",
        "    lsa_score = cal_lsa(model_answer, user_answer)\n",
        "    \n",
        "    #Calculate Sentence Similarity Score\n",
        "    ss_score, bleu_score = cal_SentenceSimilarity(model_answer, user_answer)\n",
        "\n",
        "    #Calculate Numerical Score\n",
        "    dt_score = cal_date( model_answer, user_answer)\n",
        "    \n",
        "    if(dt_score==0.0):\n",
        "        final_score = spgm_score*40 + lsa_score*20 + ss_score*20 + bleu_score*20\n",
        "    else:\n",
        "        final_score = spgm_score*40 + lsa_score*20 + ss_score*10 + bleu_score*20 + dt_score*10\n",
        "        \n",
        "    return final_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CnofaWCSPA4i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def take_input():\n",
        "    ann=[]\n",
        "    topic=[]\n",
        "    with open('/home/phaniraj/Desktop/RKD/5.txt') as f:\n",
        "        for line in f:\n",
        "            res=line.split(\"\\t\")\n",
        "            if(len(res)>1):\n",
        "                #print(res[1])\n",
        "                if(res[0]=='Q1'):\n",
        "                    topic.append(\"Non-Cooperation Movement\")\n",
        "                elif(res[0]=='Q2'):\n",
        "                    topic.append(\"Simon Commission\")\n",
        "                elif(res[0]=='Q3'):\n",
        "                    topic.append(\"Chauri Chaura\")\n",
        "                elif(res[0]=='Q4'):\n",
        "                    topic.append(\"Rowlatt Act\")\n",
        "                elif(res[0]=='Q5'):\n",
        "                    topic.append(\"Swaraj Party\")\n",
        "                ann.append(res[1])\n",
        "    return topic, ann"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "CubH7URyPA4k",
        "colab_type": "code",
        "outputId": "a702cff4-82ab-42b2-8234-55ac6495c77c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    topic, user_answers = take_input()\n",
        "    for idx, user_answer in enumerate(user_answers):\n",
        "        #print(topic[idx],user_answer)\n",
        "        #model_answer = get_model_answer(\"Salt March\")\n",
        "        #user_answer = 'The accused were denied the right to know the accusers and the evidence used in the trial. Gandhi and others thought that constitutional opposition to the measure was fruitless, so on 6 April, a hartal was organised where Indians would suspend all business and would fast, pray and hold public meetings against the Black Act as a sign of their opposition and civil disobedience would be offered against the law. This event was known as the Rowlatt Satyagraha.'\n",
        "        model_answer = get_model_answer(topic[idx])\n",
        "        #print(model_answer)\n",
        "     \n",
        "        score = cal_score( model_answer, user_answer)\n",
        "        print(score)\n",
        "        print(\"\\n\")\n",
        "except ArithmeticError:  \n",
        "        print (\"\" )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spelling and Grammer Score: 1.0\n",
            "LSA Score: 0.1601501041955279\n",
            "Sentence Similarity Score: 0.47061557365984547\n",
            "BLEU Score: 0.3757335346580497\n",
            "Date Score: 0\n",
            "60.12998425026846\n",
            "\n",
            "\n",
            "Spelling and Grammer Score: 0.9974358974358974\n",
            "LSA Score: 0.1491152598124726\n",
            "Sentence Similarity Score: 1.0000000000000002\n",
            "BLEU Score: 0.3757335346580497\n",
            "Date Score: 0\n",
            "70.39441178684635\n",
            "\n",
            "\n",
            "Spelling and Grammer Score: 1.0\n",
            "LSA Score: 0.07873446687990465\n",
            "Sentence Similarity Score: 0.35651892294281046\n",
            "BLEU Score: 0.3757335346580497\n",
            "Date Score: 0\n",
            "56.219738489615295\n",
            "\n",
            "\n",
            "Spelling and Grammer Score: 0.9912425045321435\n",
            "LSA Score: 0.08855190725799711\n",
            "Sentence Similarity Score: 0.3610331238585783\n",
            "BLEU Score: 0.3757335346580497\n",
            "Date Score: 0\n",
            "56.15607149677824\n",
            "\n",
            "\n",
            "Spelling and Grammer Score: 0.9938922151793702\n",
            "LSA Score: 0.1024667921910661\n",
            "Sentence Similarity Score: 0.8518826827522146\n",
            "BLEU Score: 0.3757335346580497\n",
            "Date Score: 0\n",
            "66.35734879920142\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0VkHaQNGPA4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SzoJsP90PA4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8rN710_PA4p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wuyPKLkAPA4q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87ClY6dWPA4t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1dkzeLZtPA4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QN4jmWgfPA4y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EELkwFYVPA40",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SFwCmQcaPA41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "veZO4kf-PA43",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tS_82eQ8PA45",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ovh-Pvk7PA47",
        "colab_type": "code",
        "outputId": "5318a9ff-0bbe-4a58-a5f0-1a309129d4a3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for user_answer in user_answers:\n",
        "#    print(user_answer)\n",
        "#    score = cal_score( model_answer, user_answer)\n",
        "#    print(score)\n",
        "\n",
        "score = cal_score( model_answer, user_answers)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spelling and Grammer Score: 1.0\n",
            "LSA Score: 0.21446393454161006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/phaniraj/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/truncated_svd.py:192: RuntimeWarning: invalid value encountered in true_divide\n",
            "  self.explained_variance_ratio_ = exp_var / full_var\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Sentence Similarity Score: 0.32979600888138694\n",
            "BLEU Score: 0.3757335346580497\n",
            "Date Score: 0\n",
            "58.39986956162094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4dF4x2MWPA49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "normalise all section marks to out of 10 or 100"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}